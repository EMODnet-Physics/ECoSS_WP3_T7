""" Script for useful functions """

import yaml
from pathlib import Path
import torch.nn as nn
import torchaudio
import torch
import os
import random

def load_yaml(yaml_path: str) -> dict:
    """Function used to load the yaml content. Useful for reading configuration files or any other data stored in YAML format.

    Args:
        yaml_path (str): The absolute path to the yaml

    Returns:
        dict: The yaml content
    """
    with open(yaml_path, 'r') as file:
        try:
            yaml_content = yaml.safe_load(file)
            return yaml_content
        except yaml.YAMLError as e:
            print(e)
            return None
        

def create_exp_dir(name: str, model: str, task: str) -> str:
    """
    Function to create a unique experiment directory. Useful for organizing experiment results by model and task.

    Args:
        name (str): The base name for the experiment directory.
        task (str): The name of the task associated with the experiment.
        model (str): The name of the model associated with the experiment.

    Returns:
        str: The path to the created experiment directory.
    """
    parent_path = Path(f'runs/{model}/{task}')
    parent_path.mkdir(exist_ok=True, parents=True)
    exp_path = str(parent_path / name) + "_{:02d}"
    i = 0
    while Path(exp_path.format(i)) in list(parent_path.glob("*")):
        i += 1
    exp_path = Path(exp_path.format(i))
    exp_path.mkdir(exist_ok=True)
    return str(exp_path)


def load_data(folder: str):
    """Function to load the wav data generated by the EcossDataset class 

    Args:
        folder (str): The path to the train or test folder

    Returns:
        list, dict: A list with the data and its associated encoder
    """
    data = []
    labels = []
    label_encoder = {}
    for idx, label in enumerate(sorted(os.listdir(folder))):
        label_path = os.path.join(folder, label)
        if os.path.isdir(label_path):
            label_encoder[label] = idx
            for file in os.listdir(label_path):
                if file.endswith('.wav'):
                    file_path = os.path.join(label_path, file)
                    data.append((file_path, idx))
    return data, label_encoder


def data_loader(data: list, mel, test: bool = False, batch_size: int = 32, shuffle: bool = True):
    """This function creates a manual data loader

    Args:
        data (list): The list with the data (tuples path label)
        mel (_type_): The AugmentedMel instance
        test (bool): If True, the augmentation is disabled.
        batch_size (int, optional): Defaults to 32.
        shuffle (bool, optional): Defaults to True.

    Yields:
        torch.Tensor: The batch of melspectrograms and labels
    """
    if shuffle:
        random.shuffle(data)
    if test:
        mel.eval()
    batch = []
    for file_path, label in data:
        waveform, sample_rate = torchaudio.load(file_path)
        mel_spectrogram = mel(waveform)
        batch.append((mel_spectrogram, label))
        if len(batch) == batch_size:
            inputs, labels = zip(*batch)
            yield torch.stack(inputs), torch.tensor(labels)
            batch = []
    if batch:  # Handle the last batch which might be smaller
        inputs, labels = zip(*batch)
        yield torch.stack(inputs), torch.tensor(labels)




class AugmentMelSTFT(nn.Module):
    """ This class is used in order to generate the mel spectrograms for the EffAT and PaSST models
    """
    def __init__(self, n_mels=128, sr=32000, win_length=800, hopsize=320, n_fft=1024, freqm=48, timem=192,
                 fmin=0.0, fmax=None, fmin_aug_range=10, fmax_aug_range=2000):
        torch.nn.Module.__init__(self)
        # adapted from: https://github.com/CPJKU/kagglebirds2020/commit/70f8308b39011b09d41eb0f4ace5aa7d2b0e806e

        self.win_length = win_length
        self.n_mels = n_mels
        self.n_fft = n_fft
        self.sr = sr
        self.fmin = fmin
        if fmax is None:
            fmax = sr // 2 - fmax_aug_range // 2
            print(f"Warning: FMAX is None setting to {fmax} ")
        self.fmax = fmax
        self.hopsize = hopsize
        self.register_buffer('window',
                             torch.hann_window(win_length, periodic=False),
                             persistent=False)
        assert fmin_aug_range >= 1, f"fmin_aug_range={fmin_aug_range} should be >=1; 1 means no augmentation"
        assert fmax_aug_range >= 1, f"fmax_aug_range={fmax_aug_range} should be >=1; 1 means no augmentation"
        self.fmin_aug_range = fmin_aug_range
        self.fmax_aug_range = fmax_aug_range

        self.register_buffer("preemphasis_coefficient", torch.as_tensor([[[-.97, 1]]]), persistent=False)
        if freqm == 0:
            self.freqm = torch.nn.Identity()
        else:
            self.freqm = torchaudio.transforms.FrequencyMasking(freqm, iid_masks=True)
        if timem == 0:
            self.timem = torch.nn.Identity()
        else:
            self.timem = torchaudio.transforms.TimeMasking(timem, iid_masks=True)

    def forward(self, x):
        # x = nn.functional.conv1d(x.unsqueeze(1), self.preemphasis_coefficient).squeeze(1)  # Makes the mels look bad
        x = torch.stft(x, self.n_fft, hop_length=self.hopsize, win_length=self.win_length,
                       center=True, normalized=False, window=self.window, return_complex=False)
        x = (x ** 2).sum(dim=-1)  # power mag
        # GOOD ONES
        fmin = self.fmin + torch.randint(self.fmin_aug_range, (1,)).item()
        fmax = self.fmax + self.fmax_aug_range // 2 - torch.randint(self.fmax_aug_range, (1,)).item()
        
        # don't augment eval data
        if not self.training:
            fmin = self.fmin
            fmax = self.fmax

        mel_basis, _ = torchaudio.compliance.kaldi.get_mel_banks(self.n_mels,  self.n_fft, self.sr,
                                        fmin, fmax, vtln_low=100.0, vtln_high=-500., vtln_warp_factor=1.0)
        mel_basis = torch.as_tensor(torch.nn.functional.pad(mel_basis, (0, 1), mode='constant', value=0),
                                    device=x.device)
        with torch.cuda.amp.autocast(enabled=False):
            melspec = torch.matmul(mel_basis, x)

        melspec = (melspec + 0.00001).log()

        if self.training:
            melspec = self.freqm(melspec)
            melspec = self.timem(melspec)

        melspec = (melspec + 4.5) / 5.  # fast normalization

        return melspec


class EffATWrapper(nn.Module):  # Wrapper
    def __init__(self, num_classes, model, freeze):
        super(EffATWrapper, self).__init__()
        self.num_classes = num_classes
        self.model = model
        if freeze:
            for param in self.model.parameters():
                param.requires_grad = False 
        
        # Replace the number of output features to match classes
        new_classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(output_size=1),
            nn.Flatten(start_dim=1, end_dim=-1),
            nn.Linear(in_features=960, out_features=1280, bias=True),
            nn.Hardswish(),
            nn.Dropout(p=0.2, inplace=True),
            nn.Linear(in_features=1280, out_features=self.num_classes, bias=True)
        )
        model.classifier = new_classifier
        print(model)
        self.model = model
        
    def forward(self, melspec):
        logits = self.model(melspec)
        return logits